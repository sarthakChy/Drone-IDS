{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1690b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/sarthak/drone_project/my_master_dataset_full.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "target = \"label\"\n",
    "groups = df[\"flight_id\"]\n",
    "X = df.drop(columns=[\"label\", \"flight_id\", \"attack_type\", \"attack_params_json\",\"timestamp\"])\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf462f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d63444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Training RandomForest\n",
      "\n",
      "ðŸ”¹ Training ExtraTrees\n",
      "\n",
      "ðŸ”¹ Training LogisticRegression\n",
      "\n",
      "ðŸ”¹ Training SVC-RBF\n",
      "\n",
      "ðŸ”¹ Training GradientBoosting\n",
      "\n",
      "ðŸ”¹ Training XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/drone_project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [18:23:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/sarthak/drone_project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [18:23:23] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/sarthak/drone_project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [18:23:24] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/sarthak/drone_project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [18:23:24] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/sarthak/drone_project/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [18:23:25] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "                Model  Accuracy        F1       AUC\n",
      "4    GradientBoosting  0.759494  0.622493  0.837373\n",
      "5             XGBoost  0.760081  0.624371  0.832890\n",
      "0        RandomForest  0.738618  0.662284  0.829851\n",
      "1          ExtraTrees  0.766998  0.504097  0.805105\n",
      "3             SVC-RBF  0.693928  0.527788  0.704970\n",
      "2  LogisticRegression  0.648457  0.494576  0.642007\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=14, class_weight='balanced',n_jobs=-1, random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=200, max_depth=12, n_jobs=-1, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight='balanced'),\n",
    "    \"SVC-RBF\": SVC(kernel=\"rbf\", probability=True, class_weight='balanced'),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200, learning_rate=0.05, max_depth=8, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'\n",
    "    )\n",
    "}\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ”¹ Training {name}\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        y_prob = (\n",
    "            pipe.predict_proba(X_test)[:, 1]\n",
    "            if hasattr(pipe.named_steps[\"model\"], \"predict_proba\")\n",
    "            else y_pred\n",
    "        )\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        fold_metrics.append((acc, f1, auc))\n",
    "\n",
    "    acc_mean = np.mean([m[0] for m in fold_metrics])\n",
    "    f1_mean = np.mean([m[1] for m in fold_metrics])\n",
    "    auc_mean = np.mean([m[2] for m in fold_metrics])\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc_mean,\n",
    "        \"F1\": f1_mean,\n",
    "        \"AUC\": auc_mean\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ea4196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "                Model  Accuracy        F1       AUC\n",
      "0        RandomForest  0.738618  0.662284  0.829851\n",
      "5             XGBoost  0.760081  0.624371  0.832890\n",
      "4    GradientBoosting  0.759494  0.622493  0.837373\n",
      "3             SVC-RBF  0.693928  0.527788  0.704970\n",
      "1          ExtraTrees  0.766998  0.504097  0.805105\n",
      "2  LogisticRegression  0.648457  0.494576  0.642007\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"F1\", ascending=False)\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1bd16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model and feature list saved.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Drop useless or categorical columns\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"label\", \"flight_id\", \"attack_type\", \"attack_params_json\",\"timestamp\"]\n",
    "]\n",
    "\n",
    "best_model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=14,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "joblib.dump(best_model, \"drone_ids_model.pkl\")\n",
    "joblib.dump(feature_cols, \"feature_list.pkl\")\n",
    "print(\"âœ… Model and feature list saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1606cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model training complete.\n",
      "âœ… Gradient Boosting model saved to 'gb_ids_model.pkl'\n",
      "âœ… Feature list saved to 'feature_list.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Drop useless or categorical columns\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"label\", \"flight_id\", \"attack_type\", \"attack_params_json\",\"timestamp\"]\n",
    "]\n",
    "\n",
    "gb_model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=14,       \n",
    "        learning_rate=0.05, \n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train the model on the FULL dataset\n",
    "gb_model.fit(X, y)\n",
    "\n",
    "print(\"âœ… Model training complete.\")\n",
    "\n",
    "# Save the model and feature list\n",
    "joblib.dump(gb_model, \"gb_ids_model.pkl\")\n",
    "joblib.dump(feature_cols, \"gb_feature_list.pkl\")\n",
    "\n",
    "print(\"âœ… Gradient Boosting model saved to 'gb_ids_model.pkl'\")\n",
    "print(\"âœ… Feature list saved to 'feature_list.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45e3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting XGBoost model training...\n",
      "Calculated scale_pos_weight for imbalance: 1.74\n",
      "âœ… Model training complete.\n",
      "âœ… XGBoost model saved to 'xgb_ids_model.pkl'\n",
      "âœ… Feature list saved to 'feature_list.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import logging\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"label\", \"flight_id\", \"attack_type\", \"attack_params_json\", \"timestamp\"]\n",
    "]\n",
    "\n",
    "print(\"ðŸš€ Starting XGBoost model training...\")\n",
    "\n",
    "# Calculate 'scale_pos_weight' for imbalanced data\n",
    "# This is the correct way to handle 'class_weight' in XGBoost\n",
    "try:\n",
    "    count_neg = (y == 0).sum()\n",
    "    count_pos = (y == 1).sum()\n",
    "    scale_pos_weight = count_neg / count_pos\n",
    "    print(f\"Calculated scale_pos_weight for imbalance: {scale_pos_weight:.2f}\")\n",
    "except ZeroDivisionError:\n",
    "    print(\"Warning: No positive samples (label=1) found. Setting scale_pos_weight to 1.\")\n",
    "    scale_pos_weight = 1\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating scale_pos_weight: {e}. Defaulting to 1.\")\n",
    "    scale_pos_weight = 1\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "xgb_model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=14,           \n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight, \n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train the model on the FULL dataset\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "print(\"âœ… Model training complete.\")\n",
    "\n",
    "# Save the model and feature list\n",
    "joblib.dump(xgb_model, \"xgb_ids_model.pkl\")\n",
    "joblib.dump(feature_cols, \"xgb_feature_list.pkl\")\n",
    "\n",
    "print(\"âœ… XGBoost model saved to 'xgb_ids_model.pkl'\")\n",
    "print(\"âœ… Feature list saved to 'feature_list.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
